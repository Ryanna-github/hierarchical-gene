---
title: "updates"
author: "renyan"
date: "2022/4/23"
output: 
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list = ls(all = TRUE))
ls()
setwd("D:/Ryanna/RUC_courses/Y1_2/Group/code")
library(Matrix)
library(MASS)
library(fmrs)
library(ggplot2)
library(corrplot)
library(dplyr)
library(reshape2)
source("sim.r")
```


# 模拟数据生成

```{r}
n <- 120                         # The sample size
p <- 10                           # The dimension of x
q <- 5                         # The dimension of z
pq <- q*p                        # The dimension of each sample
# dim_nonzero_x <- 2                         # The dimension of non-zero coefficients of x
# dim_nonzero_z <- 4                        # The dimension of non-zero coefficients of z
# E.cat <- 2                       # The dimension of non-zero coefficients of z
mu <- 6                      # The signal intensity of non-zero coefficients
balance <- T                     # Balanced/Imbalanced subgroup
gr_num_main <- 2                     # The number of rough subgroup 
gr_num_sub <- 4                       # The number of refined subgroup 
hier_struc <- list(c(1,2),c(3,4))  # Hierarchical subgroup structure
# sd.epsi<-0.5                     # The residual error
# corZX <- F                       # Correlated/Uncorrelated X and Z
intercorr0<-"AR1"                # The correlation structure of Z
signal_its <- 2 # signal intensity
K <- gr_num_sub
set.seed(9)

# ------------ Necessary parameters to support algorithm implementation --------
comb_pair <- combn(K,2)
H_3 <- kronecker(Matrix(t(apply(comb_pair,2,dMatrixFun)),sparse = T),bdiag(diag(pq)))
H_1 <- kronecker(Matrix(t(apply(comb_pair,2,dMatrixFun)),sparse = T),bdiag(diag(p)))
H_2 <- kronecker(Matrix(t(apply(comb_pair,2,dMatrixFun)),sparse = T),bdiag(diag(q)))
one_matrix_w <- bdiag(rep(list(rep(1,pq)),(K*(K-1)/2)))
one_matrix_x <- bdiag(rep(list(rep(1,q)),(K*(K-1)/2)))
one_matrix_z <- bdiag(rep(list(rep(1,p)),(K*(K-1)/2)))

# ------------ Generate the regression coefficients -----------
# coef_main_value <- c(signal_its,-signal_its)
# coef_sub_value <- c(1.5*signal_its,0.5*signal_its,-0.5*signal_its,-1.5*signal_its)
coef_main_value <- c(signal_its, -signal_its)
coef_sub_value <- c(1.5*signal_its, 0.5*signal_its, -0.5*signal_its, -1.5*signal_its)
if(balance){pr_sub<-rep(1/gr_num_sub,gr_num_sub)}else{pr_sub<-c(1/6,1/6,1/3,1/3)}

# true main groups & subgroups
ci <- ci_generate(n, pr_sub, hier_struc)
ci_main <- ci$ci_main
ci_sub <- ci$ci_sub
ci_sim <- rep(0, n)
for(i in 1:K){
  ci_sim[ci_sub[[i]]] <- i
}

# true coefficients
coef_true <- generate_coef_true(n, p, q, ci_main, ci_sub, coef_main_value, coef_sub_value)

# ------------ Generate data ------------ 
whole.data <- generate_sim_data(n, p, q, coef_true, cotype_x="AR_E", cotype_z="AR_E")
# whole.data$data_y <- whole.data$data_y + 100
```


# Model

## Initialization



- `fmrs.tunsel`: The maximizer of penalized Log-Likelihood depends on selecting a set of good tuning parameters which is a rather thorny issue. We choose a value in an equally spaced set of values in $(0, \lambda_{max})$ for a pre-specified λmax that maximize the component-wise BIC

$$\hat{\lambda}_{k}=\operatorname{argmax}_{\lambda_{k}} B I C_{k}\left(\lambda_{k}\right)=\operatorname{argmax}_{\lambda_{k}}\left\{\ell_{k, n}^{c}\left(\hat{\Psi}_{\lambda_{k}, k}\right)-\left|d_{\lambda_{k}, k}\right| \log (n)\right\}$$

where $d_{\lambda_{k}, k}=\left\{j: \hat{\beta}_{\lambda_{k}, k j} \neq 0, j=1, \ldots, d\right\}$ is the active set excluding the intercept and $\left|d_{\lambda_{k}, k}\right|$ is its size. This approach is much faster than using an nComp by nComp grid to select the set $\boldsymbol{\lambda}$ to maximize the penallized Log-Likelihood.


- `fmrs.varsel`: Provides variable selection and penalized MLE for Finite Mixture of Regression (FMR) Models. The penalized likelihood of a finite mixture of the models is written as

$$
\tilde{\ell}_{n}(\boldsymbol{\Psi})=\ell_{n}(\boldsymbol{\Psi})-\mathbf{p}_{\boldsymbol{\lambda}_{n}}(\boldsymbol{\Psi})
$$

where 

$$
\mathbf{p}_{\boldsymbol{\lambda}_{n}}(\boldsymbol{\Psi})=\sum_{k=1}^{K} \pi_{k}^{\alpha}\left\{\sum_{j=1}^{d} p_{\lambda_{n, k}}\left(\beta_{k j}\right)\right\}
$$

- Estimation
    - 分类的类别编号和真实编号未必相同，对分类效果采用如下指标
    
$$
\begin{aligned}
\operatorname{SC}(\widehat{\varphi}, \varphi): &=\left(\begin{array}{l}
n \\
2
\end{array}\right)^{-1} \mid\left\{(i, j): I\left(\widehat{\varphi}\left(\boldsymbol{x}_{i}, \boldsymbol{z}_{i}\right)=\widehat{\varphi}\left(\boldsymbol{x}_{j}, \boldsymbol{z}_{j}\right)\right)\right.\\
&\left.=I\left(\varphi\left(\boldsymbol{x}_{i}, \boldsymbol{z}_{i}\right)=\varphi\left(\boldsymbol{x}_{j}, \boldsymbol{z}_{j}\right)\right) ; i<j\right\} \mid
\end{aligned}
$$

```{r}
initialize_coef <- function(whole.data, p, q, K_up = 4, int_rm = TRUE) {
  pq <- p * q
  as <- matrix(1, nrow = p + q + pq + 1, ncol = K_up) # activeset parameter in fmrs package
  if (int_rm) { as[1, ] <- 0 }
  # init of init
  coef_rough_init <- rnorm(K_up * (p + q + pq + 1))
  res.mle <- fmrs.mle(y = whole.data$data_y,
                      x = whole.data$X_all,
                      delta = rep(0, length(whole.data$data_y)),
                      nComp = K_up,
                      disFamily = "norm",
                      initCoeff = coef_rough_init,
                      initDispersion = rep(1, K_up),
                      initmixProp = rep(1 / K_up, K_up),
                      nIterNR = 200,
                      activeset = as)
  res.lam <- fmrs.tunsel(y = whole.data$data_y, 
                       x = whole.data$X_all, 
                       delta = rep(0, length(whole.data$data_y)),
                       nComp = K_up, 
                       disFamily = "norm",
                       initCoeff = c(coefficients(res.mle)),
                       initDispersion = dispersion(res.mle),
                       initmixProp = mixProp(res.mle),
                       penFamily = "mcp", 
                       nIterNR = 200,
                       activeset = as)
  # res.lam@lambPen
  res.var <- fmrs.varsel(y = whole.data$data_y, 
                       x = whole.data$X_all, 
                       delta = rep(0, length(whole.data$data_y)),
                       nComp = ncomp(res.mle), 
                       disFamily = "norm",
                       initCoeff = c(coefficients(res.mle)),
                       initDispersion = dispersion(res.mle),
                       initmixProp = mixProp(res.mle),
                       penFamily = "mcp",
                       lambPen = slot(res.lam, "lambPen"), 
                       nIterNR = 200)
  # res.var@dispersion
  # res.var@mixProp
  
  # cluster result
  fmr_weight_ci <- apply(res.var@weights, 1, which.max)
  fmr_res_ci <- apply(abs(res.var@residuals), 1, which.min) 
  fmr_res <- c()
  fmr_weight <- c()
  fmr_weight_y <- c()
  fmr_res_y <- c()
  for (i in 1:n) {
    fmr_res[i] <- res.var@residuals[i, fmr_res_ci[i]]
    fmr_weight[i] <- res.var@weights[i, fmr_weight_ci[i]]
    fmr_res_y[i] <- res.var@fitted[fmr_res_ci[i]]
    fmr_weight_y[i] <- res.var@fitted[fmr_weight_ci[i]]
  }
  fmr_var <- sqrt(sum(fmr_res^2))
  fmr_bic <- res.var@BIC
  fmr_coe <- res.var@coefficients
  if(int_rm){ fmr_coe <- res.var@coefficients[-1,]}
  coef_init <- as.vector(fmr_coe)
  
  rho_k_weight <- c()
  rho_k_res <- c()
  mu_k_weight <- c()
  mu_k_res <- c()
  for(k in 1:4){
    rho_k_weight[k] <- 1/sd(whole.data$data_y[fmr_weight_ci == k])
    rho_k_res[k] <- 1/sd(whole.data$data_y[fmr_res_ci == k])
    mu_k_weight[k] <- mean(whole.data$data_y[fmr_res_ci == k])
    mu_k_res[k] <- mean(whole.data$data_y[fmr_res_ci == k])
  }
  
  return(list(ci_weight = fmr_weight_ci,
              ci_res = fmr_res_ci,
              y_weight = fmr_weight_y,
              y_res = fmr_res_y,
              mu_k_weight = mu_k_weight,
              mu_k_res = mu_k_res,
              pi_k = res.var@mixProp,
              rho_k_weight = rho_k_weight,
              rho_k_res = rho_k_res,
              info = list(bic = fmr_bic,
                          coef = fmr_coe,
                          sd = fmr_var)))
}
```

```{r}
# 评价分类效果
sc <- function(ci_est, ci_true){
  if(length(ci_est) != length(ci_true)){
    stop("Wrong len of ci's")
  }
  n <- length(ci_sim)
  comb_matrix <- combn(n, 2)
  scs <- NULL
  for(pair_idx in 1:ncol(comb_matrix)){
    scs <- c(scs, (ci_est[comb_matrix[,pair_idx]][1] == ci_est[comb_matrix[,pair_idx]][2]) ==
       (ci_true[comb_matrix[,pair_idx]][1] == ci_true[comb_matrix[,pair_idx]][2]))
  }
  return(mean(scs))
}
```

```{r}
set.seed(99)
fmr <- initialize_coef(whole.data, p, q)
```

```{r}
table(ci_sim, fmr$ci_weight)
table(ci_sim, fmr$ci_res)
prop.table(table(fmr$ci_weight))
prop.table(table(fmr$ci_res))
```



```{r}
sc(fmr$ci_weight, ci_sim)
sc(fmr$ci_res, ci_sim)
sc(fmr$ci_res, fmr$ci_weight)
```

```{r}
# ggplot(data.frame(y = whole.data$data_y, y_weight = fmr$y_weight, y_res = fmr$y_res)) +
#   geom_point(aes(x = y, y = y_weight)) +
#   geom_point(aes(x = y, y = y_res), col = "red", alpha = 0.6) +
#   theme_minimal()
```

```{r}
# sc_weight <- NULL
# sc_res <- NULL
# for(i in 1:100){
#   fmr <- initialize_coef(whole.data, p, q)
#   sc_weight <- c(sc_weight, sc(fmr$ci_weight, ci_sim))
#   sc_res <- c(sc_res, sc(fmr$ci_res, ci_sim))
# }
# write.csv(data.frame(sc_weight = sc_weight, sc_res = sc_res), file = "sc.csv", row.names = FALSE)
df_sc <- read.csv("sc.csv") %>% melt()
ggplot(df_sc, aes(x = value, fill = variable)) +
  geom_histogram(position = 'dodge') +
  theme_minimal()
```

```{r}
iter_max <- 10
coef_init <- fmr$info$coef

idx_X <- c(1:(p))
idx_Z <- c((p+1):((p+q)))
idx_W <- c(((p+q)+1):((p+q+pq)))
idx_X_full <- sort(rep((0:(K-1))*(p+q+pq), p)) + idx_X
idx_Z_full <- sort(rep((0:(K-1))*(p+q+pq), q)) + idx_Z
idx_W_full <- sort(rep((0:(K-1))*(p+q+pq), pq)) + idx_W
coef_init_beta <- coef_init[idx_X_full]
coef_init_alpha <- coef_init[idx_Z_full]
coef_init_gamma <- coef_init[idx_W_full]

X <- whole.data$X_all
X_full <- whole.data$data_X_all
y <- whole.data$data_y

####################### Initialize coef ######################
# group
u_init <- H_1 %*% coef_init_beta
v_init <- H_2 %*% coef_init_alpha
w_init <- H_3 %*% coef_init_gamma
xi_init <- Matrix(0, ncol=1, nrow=p*K*(K-1)/2, sparse=T)
zeta_init <- Matrix(0, ncol=1, nrow=q*K*(K-1)/2, sparse=T)
eta_init <- Matrix(0, ncol=1, nrow=pq*K*(K-1)/2, sparse=T)

# iteration
iter <- 1
coef_beta_est_list <- vector(mode="list", length=iter_max)
coef_alpha_est_list <- vector(mode="list", length=iter_max)
coef_gamma_est_list <- vector(mode="list", length=iter_max)
coef_beta_est_list[[iter]] <- coef_init_beta
coef_alpha_est_list[[iter]] <- coef_init_alpha
coef_gamma_est_list[[iter]] <- coef_init_gamma

u_est_list <- vector(mode="list", length=iter_max); u_est_list[[iter]] <- u_init
v_est_list <- vector(mode="list", length=iter_max); v_est_list[[iter]] <- v_init
w_est_list <- vector(mode="list", length=iter_max); w_est_list[[iter]] <- w_init

xi_est_list <- vector(mode="list", length=iter_max)
zeta_est_list <- vector(mode="list", length=iter_max)
eta_est_list <- vector(mode="list", length=iter_max)
xi_est_list[[iter]] <- xi_init
zeta_est_list[[iter]] <- zeta_init
eta_est_list[[iter]] <- eta_init

rho_est_list <- vector(mode="list", length=iter_max)
rho_est_list[[iter]] <- fmr$rho_k_weight
mu_est_list <- vector(mode="list", length=iter_max)
mu_est_list[[iter]] <- fmr$mu_k_weight
pi_est_list <- vector(mode="list", length=iter_max)
pi_est_list[[iter]] <- fmr$pi_k

y_est_list <- vector(mode="list", length=iter_max)
y_est_list[[iter]] <- fmr$y_weight
```

ADMM 算法循环体

```{r}
K_up <- 4
tau <- 1 

H_1_prod <- t(H_1)%*%H_1
H_2_prod <- t(H_2)%*%H_2
H_3_prod <- t(H_3)%*%H_3

lambda_1 <- 1
lambda_2 <- 1
lambda_3 <- 1
a <- 3

for(iter in 2:iter_max){
  pi_k <- pi_est_list[[iter-1]]
  q_c_matrix <- matrix(0, nrow = n, ncol = K_up)
  for(k in 1:K_up){
    q_c_matrix[,k] <- dnorm(y_est_list[[iter-1]],
                            mean = mu_est_list[[iter-1]][k],
                            sd = 1/rho_est_list[[iter-1]][k])
  }
  q_c_matrix <- q_c_matrix * kronecker(matrix(1, nrow = n, ncol = 1), matrix(pi_k, nrow=1))
  q_c_matrix <- q_c_matrix/apply(q_c_matrix, 1, sum)
  
  # ======================================= PART 1 ======================================= 
  for(k in 1:K_up){
    b_k_common <- 1/tau * sum(q_c_matrix[,k] * 
                                rho_est_list[[iter-1]]**2 * 
                                (whole.data$data_y - mu_est_list[[iter-1]]))
    # -------------------------------------- PART 1.1 --------------------------------------
    # alpha_k
    A_k <- (H_2_prod)[((k-1)*q+1):(k*q),]
    b_k1 <- t(H_2)[((k-1)*q+1):(k*q),]%*%(v_est_list[[iter-1]]-1/tau*zeta_est_list[[iter-1]])
    b_k2 <- apply(q_c_matrix[,k] * whole.data$Z, 2, sum)
    b_k <- b_k1 + b_k_common * b_k2
    coef_alpha_est_list[[iter]][((k-1)*q+1):(k*q)] <- qr.solve(A_k, b_k)[1:q]
    
    # -------------------------------------- PART 1.2 --------------------------------------
    # beta_k
    beta_k <- coef_beta_est_list[[iter-1]][((k-1)*p+1):(k*p)]
    gamma_k <- coef_gamma_est_list[[iter-1]][((k-1)*pq+1):(k*pq)]
    beta_comp_case <- (abs(beta_k) <= a*lambda_1) # beta_kj <= a*lambda_1 case
  
    A_k <- (H_1_prod)[((k-1)*p+1):(k*p),]
    b_k1 <- t(H_1)[((k-1)*p+1):(k*p),]%*%(u_est_list[[iter-1]]-1/tau*xi_est_list[[iter-1]])
    b_k2 <- apply(q_c_matrix[,k] * (whole.data$X + as.numeric(whole.data$W%*%matrix(gamma_k, ncol=1))), 2, sum)
    b_k <- b_k1 + b_k_common * b_k2
    coef_beta_est_list[[iter]][((k-1)*p+1):(k*p)] <- qr.solve(A_k, b_k)[1:p]
    for(j in which(beta_comp_case == TRUE)){
      A_kj <- (H_1_prod)[((k-1)*p+j),((k-1)*p+j)] - 1/(a*lambda_1)*sign(beta_k[j])
      b_kj1 <- (t(H_1)[((k-1)*p+1):(k*p),]%*%(u_est_list[[iter-1]]-1/tau*xi_est_list[[iter-1]]) - lambda_1/a)[j]
      b_kj2 <- (apply(q_c_matrix[,k] * (whole.data$X + as.numeric(whole.data$W%*%matrix(gamma_k, ncol=1))), 2, sum))[j]
      b_kj <- b_kj1 + b_k_common * b_kj2
      coef_beta_est_list[[iter]][((k-1)*p+1):(k*p)][j] <- b_kj/A_kj
    }
    
    # -------------------------------------- PART 1.3 --------------------------------------
    # gamma_k
    beta_k <- coef_beta_est_list[[iter-1]][((k-1)*p+1):(k*p)]
    gamma_k <- coef_gamma_est_list[[iter-1]][((k-1)*pq+1):(k*pq)]
    gamma_comp_case <- (abs(gamma_k) <= a*lambda_1) # gamma_ksj <= a*lambda_1 case
  
    A_k <- (H_3_prod)[((k-1)*pq+1):(k*pq),]
    b_k1 <- t(H_3)[((k-1)*pq+1):(k*pq),]%*%(w_est_list[[iter-1]]-1/tau*eta_est_list[[iter-1]])
    b_k2 <- sum(q_c_matrix[,k] * as.numeric(whole.data$W%*%matrix(rep(beta_k, q), ncol=1)))
    b_k <- b_k1 + b_k_common * b_k2
    coef_gamma_est_list[[iter]][((k-1)*pq+1):(k*pq)] <- qr.solve(A_k, b_k)[1:pq]
    for(sj in which(beta_comp_case == TRUE)){
      A_ksj <- (H_3_prod)[((k-1)*pq+sj),((k-1)*pq+sj)] - 1/(a*lambda_1)*sign(gamma_k[sj])
      b_ksj1 <- (t(H_3)[((k-1)*pq+1):(k*pq),]%*%(w_est_list[[iter-1]]-1/tau*eta_est_list[[iter-1]]) - lambda_1/a)[sj]
      b_ksj2 <- sum(q_c_matrix[,k] * as.numeric(whole.data$W%*%matrix(rep(beta_k, q), ncol=1)))
      b_ksj <- b_ksj1 + b_k_common * b_ksj2
      coef_gamma_est_list[[iter]][((k-1)*p+1):(k*p)][j] <- b_kj/A_kj
    }
  }
  # ======================================= PART 2 ======================================= 
  for(k in 1:K_up){
    u_hat <- H_1 %*% coef_beta_est_list[[iter]] + 1/tau * xi_est_list[[iter-1]]
    v_hat <- H_2 %*% coef_alpha_est_list[[iter]] + 1/tau * zeta_est_list[[iter-1]]
    w_hat <- H_3 %*% coef_gamma_est_list[[iter]] + 1/tau * eta_est_list[[iter-1]]
    u_hat_matrix <- matrix(u_hat, nrow = p)
    v_hat_matrix <- matrix(v_hat, nrow = q)
    w_hat_matrix <- matrix(w_hat, nrow = pq)
    
    # all hats
    phi_norm2_1 <- apply(rbind(u_hat_matrix, v_hat_matrix, w_hat_matrix), 
                         2, function(x){sqrt(sum(x**2))})
    ps_norm2_1 <- apply(rbind(u_hat_matrix, v_hat_matrix), 
                        2, function(x){sqrt(sum(x**2))})
    w_norm2_1 <- apply(w_hat_matrix, 2, function(x){sqrt(sum(x**2))})
    
    phi_coe <- abs(1-lambda_2/tau/phi_norm2_1)
    ps_coe <- abs(1-lambda_3/tau/ps_norm2_1)
    kkpair_idx_nn <- which((phi_norm2_1>a*lambda_2) & (ps_norm2_1>a*lambda_3))
    kkpair_idx_sn <- which((phi_coe*phi_norm2_1<=a*lambda_2) & (ps_coe*ps_norm2_1>a*lambda_3))
    kkpair_idx_ns <- which(((phi_coe*phi_norm2_1)**2+(w_norm2_1)**2>(a*lambda_2)**2) &
                             (ps_coe*ps_norm2_1<=a*lambda_3))
    kkpair_idx_ss <- setdiff(1:(K_up*(K_up-1)/2),
                             Reduce(union,list(kkpair_idx_nn,kkpair_idx_sn,kkpair_idx_ns)))
    
    u_est_list[[iter]] <- matrix(0, nrow = p*(K_up*(K_up-1)/2))
    v_est_list[[iter]] <- matrix(0, nrow = q*(K_up*(K_up-1)/2))
    w_est_list[[iter]] <- matrix(0, nrow = pq*(K_up*(K_up-1)/2))
    # case1: no shrinkage
    if(length(kkpair_idx_nn) > 0){
      for(kk in kkpair_idx_nn){
        u_est_list[[iter]][((kk-1)*p+1):(kk*p)] <- u_hat[((kk-1)*p+1):(kk*p)]
        v_est_list[[iter]][((kk-1)*q+1):(kk*q)] <- v_hat[((kk-1)*q+1):(kk*q)]
        w_est_list[[iter]][((kk-1)*pq+1):(kk*pq)] <- w_hat[((kk-1)*pq+1):(kk*pq)]
      }
    }
    # case2: overall shrinkage (prop)
    if(length(kkpair_idx_sn > 0)){
      for(kk in kkpair_idx_nn){
        u_est_list[[iter]][((kk-1)*p+1):(kk*p)] <- phi_coe[kk] * u_hat[((kk-1)*p+1):(kk*p)]
        v_est_list[[iter]][((kk-1)*q+1):(kk*q)] <- phi_coe[kk] * v_hat[((kk-1)*q+1):(kk*q)]
        w_est_list[[iter]][((kk-1)*pq+1):(kk*pq)] <- phi_coe[kk] * w_hat[((kk-1)*pq+1):(kk*pq)]
      }
    }
    if(length(kkpair_idx_ns > 0)){
      for(kk in kkpair_idx_nn){
        u_est_list[[iter]][((kk-1)*p+1):(kk*p)] <- ps_coe[kk] * u_hat[((kk-1)*p+1):(kk*p)]
        v_est_list[[iter]][((kk-1)*q+1):(kk*q)] <- ps_coe[kk] * v_hat[((kk-1)*q+1):(kk*q)]
        w_est_list[[iter]][((kk-1)*pq+1):(kk*pq)] <- w_hat[((kk-1)*pq+1):(kk*pq)]
      }
    }
    if(length(kkpair_idx_ss > 0)){
      for(kk in kkpair_idx_nn){
        u_est_list[[iter]][((kk-1)*p+1):(kk*p)] <- u_hat[((kk-1)*p+1):(kk*p)]/
                    (1+(lambda_2/phi_norm2_1[kk]-1/a)/tau+(lambda_3/ps_norm2_1[kk]-1/a)/tau)
        v_est_list[[iter]][((kk-1)*q+1):(kk*q)] <- v_hat[((kk-1)*q+1):(kk*q)]/
                    (1+(lambda_2/phi_norm2_1[kk]-1/a)/tau+(lambda_3/ps_norm2_1[kk]-1/a)/tau)
        w_est_list[[iter]][((kk-1)*pq+1):(kk*pq)] <- w_hat[((kk-1)*pq+1):(kk*pq)]/
                    (1+(lambda_2/phi_norm2_1[kk]-1/a)/tau+(lambda_3/ps_norm2_1[kk]-1/a)/tau)
      }
    }
  }
  
  # ======================================= PART 3 =======================================
  xi_est_list[[iter]] <- xi_est_list[[iter-1]] + 
    tau*(H_1 %*% coef_beta_est_list[[iter]] - u_est_list[[iter-1]])
  zeta_est_list[[iter]] <- zeta_est_list[[iter-1]] + 
    tau*(H_2 %*% coef_alpha_est_list[[iter]] - v_est_list[[iter-1]])
  eta_est_list[[iter]] <- eta_est_list[[iter-1]] + 
    tau*(H_3 %*% coef_gamma_est_list[[iter]] - w_est_list[[iter-1]])
  
  # ======================================= PART 4 ======================================= 
  # rho
  coef_eta <- kronecker(coef_beta_est_list[[iter]], matrix(1, q, 1)) * coef_gamma_est_list[[iter]]
  
  y_est_list[[iter]] <- apply((whole.data$X %*% matrix(coef_beta_est_list[[iter]], ncol=K_up) + 
    whole.data$Z %*% matrix(coef_alpha_est_list[[iter]], ncol=K_up) + 
    whole.data$W %*% matrix(coef_eta, ncol=K_up)) * q_c_matrix, 1, sum)
  
  rho_est_list[[iter]] <- sqrt(apply(q_c_matrix, 2, sum) /
    (apply(kronecker(y_est_list[[iter]], matrix(1, nrow=1, ncol=K_up)) - 
           kronecker(matrix(pi_est_list[[iter-1]], nrow=1), matrix(1, nrow=n, ncol=1)), 2, sum))**2)
  
  mu_est_list[[iter]] <- (whole.data$X %*% matrix(coef_beta_est_list[[iter]], ncol=K_up) + 
    whole.data$Z %*% matrix(coef_alpha_est_list[[iter]], ncol=K_up) + 
    whole.data$W %*% matrix(coef_eta, ncol=K_up)) * q_c_matrix
  mu_est_list[[iter]] <- apply(mu_est_list[[iter]], 2, mean)
  
  # ====================================== E 步补充 ====================================== 
  # 此步更新，mu，qc 更新在 M 步之前完成
  pi_est_list[[iter]] <- apply(q_c_matrix, 2, mean)
}
```

```{r}
pi_est_list
```

```{r}
lapply(y_est_list, mean)
```

```{r}
coef_beta_est_list
coef_alpha_est_list
coef_gamma_est_list
```

```{r}
ci_current <- apply(q_c_matrix, 1, which.max)
ci_current
sc(ci_current, ci_sim)
```


# 现存问题

- $\rho$ 的设定，不同分组公用还是每个组单独定义
- u,v,w 更新最后一种情况细节




